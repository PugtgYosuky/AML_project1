{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_path = os.path.join('logs')\n",
    "dirs = os.listdir(dirs_path)\n",
    "# dirs = [f'exp{i}' for i in range(86, 92+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_config(path, columns):\n",
    "    path = os.path.join(path, 'grid_search')\n",
    "    metrics = ['f1_weighted','matthews_corrcoef', 'balanced_accuracy']\n",
    "    aux = pd.DataFrame()\n",
    "    for file in os.listdir(path):\n",
    "        df = pd.read_csv(os.path.join(path, file))\n",
    "        data = pd.DataFrame()\n",
    "        filename = file.split('_')[0]\n",
    "        data['config'] = df['params']\n",
    "        data['model'] = filename\n",
    "        for metric in metrics:\n",
    "            data[f'avg_{metric}'] = df[f'mean_test_{metric}']\n",
    "            data[f'std_{metric}'] = df[f'std_test_{metric}']\n",
    "        data = data[columns]\n",
    "        sorted_results = data.sort_values(by=['avg_matthews_corrcoef', 'avg_f1_weighted'])\n",
    "        sorted_results = sorted_results.iloc[:min(len(sorted_results), 5)]\n",
    "        aux = pd.concat([aux, sorted_results], ignore_index=True)\n",
    "    return aux\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_metric(path):\n",
    "    path = os.path.join(path, 'model_metrics.csv')\n",
    "    if not os.path.exists(path):\n",
    "        return pd.DataFrame()\n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    mean = data.groupby(['model','config']).mean()\n",
    "    mean = mean.reset_index()\n",
    "\n",
    "    std =  data.groupby(['model','config']).std()\n",
    "    std = std.reset_index()\n",
    "    metrics = ['f1_weighted','matthews_corrcoef', 'balanced_accuracy']\n",
    "\n",
    "    new_data = pd.DataFrame()\n",
    "    new_data['model'] = mean['model']\n",
    "    new_data['config'] = mean['config']\n",
    "\n",
    "    for i in metrics:\n",
    "        new_data[\"avg_\"+i] = mean[i]\n",
    "        new_data[\"std_\"+i] = std[i]\n",
    "\n",
    "    return new_data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model', 'config', 'avg_f1_weighted', 'std_f1_weighted', 'avg_matthews_corrcoef', 'std_matthews_corrcoef', 'avg_balanced_accuracy', 'std_balanced_accuracy']\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "metrics = ['f1_weighted','matthews_corrcoef', 'balanced_accuracy']\n",
    "columns = ['model', 'config']\n",
    "\n",
    "for metric in metrics:\n",
    "        columns.append(f'avg_{metric}')\n",
    "        columns.append(f'std_{metric}')\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp00\n",
      "exp01\n",
      "exp02\n",
      "exp03\n",
      "exp04\n",
      "exp05\n",
      "exp06\n",
      "exp07\n",
      "exp08\n",
      "exp09\n",
      "exp10\n",
      "exp41\n",
      "exp51\n",
      "exp62\n",
      "exp63\n",
      "exp64\n",
      "exp65\n",
      "exp66\n",
      "exp67\n",
      "exp68\n",
      "exp69\n",
      "exp70\n",
      "exp71\n",
      "exp72\n",
      "exp73\n",
      "exp74\n",
      "exp75\n",
      "exp76\n",
      "exp77\n",
      "exp78\n",
      "exp79\n",
      "exp80\n",
      "exp83\n",
      "exp84\n",
      "exp85\n",
      "exp86\n",
      "exp87\n",
      "exp88\n",
      "exp89\n",
      "exp90\n",
      "exp91\n",
      "exp92\n",
      "exp93\n",
      "exp94\n"
     ]
    }
   ],
   "source": [
    "for d in dirs:\n",
    "    path = os.path.join(dirs_path, d)\n",
    "    print(d)\n",
    "    if d == 'exp00':\n",
    "        continue\n",
    "    with open(os.path.join(path, 'config.json'), 'r') as file:\n",
    "        config = json.load(file)\n",
    "        if config.get('grid_search', False):\n",
    "            df = get_data_from_config(path, columns)\n",
    "        else:\n",
    "            df = get_data_from_metric(path)\n",
    "        if len(df) != 0:\n",
    "            df['norm_model'] = config.get('norm_model', 'Standard')\n",
    "            df['columns_to_drop'] = str(config.get('columns_to_drop', []))\n",
    "            df['number_best_features'] = config.get('number_best_features', 'all')\n",
    "            df['variance_threshold'] = config.get('variance_threshold', 0)\n",
    "            df['balance_dataset'] = config.get('balance_dataset', 'null')\n",
    "            df['exp'] = f'joana {d}'\n",
    "            data = pd.concat([data, df], ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('results_mean_std_lasts.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
